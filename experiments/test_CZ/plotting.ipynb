{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import tqdm\n",
    "import glob\n",
    "from imp import reload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import deltascope as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02-18-09-56_landmarks.csv'] ['02-18-09-56_landmarks_bins.json']\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# -------- User input ------------\n",
    "# --------------------------------\n",
    "\n",
    "# Specify path to exported landmark data\n",
    "lmpath = glob.glob('*landmarks.csv')\n",
    "binpath = glob.glob('*landmarks_bins.json')\n",
    "print(lmpath,binpath)\n",
    "\n",
    "# Pick the correct path from the list\n",
    "lmpath = lmpath[0]\n",
    "binpath = binpath[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load landmarks from csv\n",
    "oldlm = pd.read_csv(lmpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load landmark bins \n",
    "with open(binpath,'r') as f:\n",
    "    bins = json.load(f)\n",
    "acbins = bins['acbins']\n",
    "tbins = bins['tbins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ['#41ab5d','#ef3b2c','#00441b','#67000d']\n",
    "tarr = np.round(tbins,2)\n",
    "xarr = np.round(acbins,2)\n",
    "tpairs = [[tarr[0],tarr[4]],[tarr[1],tarr[5]],[tarr[2],tarr[6]],[tarr[3],tarr[7]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restructure Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sort landmark data according to stype and organize it in a two tiered dictionary according to sample type (s) and channel (c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 454.35it/s]\n"
     ]
    }
   ],
   "source": [
    "Dlm = {}\n",
    "for stype in tqdm.tqdm(oldlm.stype.unique()):\n",
    "    # These two lines may need to be modified based on stype structure\n",
    "    s = stype.split('-')[0]\n",
    "    c = stype.split('-')[-1]\n",
    "    \n",
    "    # Add sample type dictionary if not already present\n",
    "    if s not in Dlm.keys():\n",
    "        Dlm[s] = {}\n",
    "    \n",
    "    # Save sample specific landmark data to dictionary\n",
    "    Dlm[s][c] = oldlm[oldlm.stype==stype]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'you'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e93926a3b8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m gs.add_data(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDlm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'you'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZRF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     'you','zrf',dtype)\n\u001b[1;32m      7\u001b[0m gs.add_data(\n",
      "\u001b[0;31mKeyError\u001b[0m: 'you'"
     ]
    }
   ],
   "source": [
    "gs = ds.graphSet(tpairs,xarr,tarr)\n",
    "dtype = 'r'\n",
    "\n",
    "gs.add_data(\n",
    "    ds.graphData(Dlm['you']['ZRF'],colors[3]),\n",
    "    'you','zrf',dtype)\n",
    "gs.add_data(\n",
    "    ds.graphData(Dlm['wt']['ZRF'],colors[1]),\n",
    "    'wt','zrf',dtype)\n",
    "gs.add_data(\n",
    "    ds.graphData(Dlm['you']['AT'],colors[2]),\n",
    "    'you','at',dtype)\n",
    "gs.add_data(\n",
    "    ds.graphData(Dlm['wt']['AT'],colors[0]),\n",
    "    'wt','at',dtype)\n",
    "\n",
    "gs.make_figure(0.3,'you',figsize=(10,20),P=True,pthresh=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
