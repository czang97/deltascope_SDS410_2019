{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deltascope as ds\n",
    "import deltascope.alignment as ut\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify matplotlib plots to be interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data\n",
    "The user needs to specify the directories containing the data of interest. Each sample type should have a key which corresponds to the directory path. Additionally, each object should have a list that includes the channels of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# -------- User input ------------\n",
    "# --------------------------------\n",
    "\n",
    "data = {\n",
    "    # Specify sample type key\n",
    "    'wt': {\n",
    "        # Specify path to data directory\n",
    "        'path': 'Output_01-04-14-43',\n",
    "        # Specify which channels are in the directory and are of interest\n",
    "        'channels': ['AT','ZRF']\n",
    "    },\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll generate a list of pairs of stypes and channels for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pairs = []\n",
    "for s in data.keys():\n",
    "    for c in data[s]['channels']:\n",
    "        data_pairs.append((s,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read in all datafiles specified by the `data` dictionary above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path\\to\\\\data\\\\directory\\\\sample1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-27dcfe54200b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_psi_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/deltascope_SDS410_2019/deltascope/__init__.py\u001b[0m in \u001b[0;36mread_psi_to_dict\u001b[0;34m(directory, dtype)\u001b[0m\n\u001b[1;32m   1800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m         \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1803\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'psi'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m                         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_psi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path\\to\\\\data\\\\directory\\\\sample1'"
     ]
    }
   ],
   "source": [
    "D = {}\n",
    "for s in data.keys():\n",
    "    D[s] = {}\n",
    "    for c in data[s]['channels']:\n",
    "        D[s][c] = ds.read_psi_to_dict(data[s]['path'],c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate optimum landmark parameters\n",
    "Choose a single sample type and channel which will be used as the control to calculate the appropriate size of landmark bins. Typically we use wildtype samples and the AT channel. We will run a parameter sweep of bin sizes using `ds.anumSelect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# -------- User input ------------\n",
    "# --------------------------------\n",
    "\n",
    "# Specify stype to use as control\n",
    "s_ctrl = 'wt'\n",
    "# Specify channel to use as control\n",
    "c_ctrl = 'AT'\n",
    "\n",
    "# Specify size of theta bins\n",
    "theta_step = np.pi/4\n",
    "# Specify the step size when sweeping various alpha bin sizes\n",
    "astep = 3\n",
    "# Specify minimum a value \n",
    "amn = 2\n",
    "# Specify maximum a value\n",
    "amx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-ad66f75f6208>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-ad66f75f6208>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    rnull=np.nan, DT='r')\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "optr = ds.anumSelect(D[s_ctrl][c_ctrl])\n",
    "optr.param_sweep(theta_step, amn=amn, amx=amx, astep=astep\n",
    "                 rnull=np.nan, DT='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot result of the parameter sweep to get a sense of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# -------- User input ------------\n",
    "# --------------------------------\n",
    "\n",
    "# Select degrees of freedom for curve fitting\n",
    "dof = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(amn,amx,astep)\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Fit a curve to bin variance values\n",
    "pbv = np.polyfit(x, normalize(optr.Mbv)[0], dof)\n",
    "fbv = np.poly1d(pbv)\n",
    "ax.plot(x, fbv(x), c='b', label='Bin Variance')\n",
    "\n",
    "# Fit curve to sample variance values\n",
    "psv = np.polyfit(x, normalize(optr.Msv)[0], dof)\n",
    "fsv = np.poly1d(psv)\n",
    "ax.plot(x, fsv(x), c='g', label='Sample Variance')\n",
    "\n",
    "# Plot sum of sample and bin variances\n",
    "ax.plot(x, fsv(x)+fbv(x), c='c', label='Total Variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the optimal bin size with the help of the user specifying a best guess for the optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# -------- User input ------------\n",
    "# --------------------------------\n",
    "\n",
    "# Guess the approximate optimal value\n",
    "guess = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = minimize(fbv+fsv, guess)\n",
    "ax.axvline(opt.x, c='r', label='Optimum: '+str(np.round(opt.x[0], 2)))\n",
    "print(opt.x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate landmark bins\n",
    "Based on the analysis above, we can select the optimal value of alpha bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# -------- User input ------------\n",
    "# --------------------------------\n",
    "\n",
    "# Pick an integer value for bin number based on results above\n",
    "anum = int(opt.x[0])\n",
    "\n",
    "# Specify the percentiles which will be used to calculate landmarks\n",
    "percbins = [50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate landmark bins based on user input parameters and the previously specified control sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ds.landmarks(percbins=percbins, rnull=np.nan)\n",
    "lm.calc_bins(D[s_ctrl][c_ctrl], anum, theta_step)\n",
    "\n",
    "print('Alpha bins')\n",
    "print(lm.acbins)\n",
    "print('Theta bins')\n",
    "print(lm.tbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdf = pd.DataFrame()\n",
    "\n",
    "# Loop through each pair of stype and channels\n",
    "for s,c in tqdm.tqdm(data_pairs):\n",
    "    print(s,c)\n",
    "    # Calculate landmarks for each sample with this data pair\n",
    "    for k,df in tqdm.tqdm(D[s][c].items()):\n",
    "        lmdf = lm.calc_perc(df, k, '-'.join([s,c]), lmdf)\n",
    "        \n",
    "# Set timestamp for saving data\n",
    "tstamp = time.strftime(\"%m-%d-%H-%M\",time.localtime())\n",
    "        \n",
    "# Save completed landmarks to a csv file\n",
    "lmdf.to_csv(tstamp+'_landmarks.csv')\n",
    "\n",
    "# Save landmark bins to json file\n",
    "bins = {\n",
    "    'acbins':list(lm.acbins),\n",
    "    'tbins':list(lm.tbins)\n",
    "}\n",
    "with open(tstamp+'_landmarks_bins.json', 'w') as outfile:\n",
    "    json.dump(bins, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
